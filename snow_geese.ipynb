{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5efb3cc",
   "metadata": {},
   "source": [
    "# Analysis and data mining of snow geese\n",
    "Author: Yihe Zhao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2519c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import GooseUtils\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Supress warning related to data types (will get on first import of the csv file)\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.DtypeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9c2085",
   "metadata": {},
   "source": [
    "Import and trim relevant data. This notebook focuses only on data related to the Anser caerulescens caerulescens (species id: 1690) and Anser caerulescens atlantica (species id: 1699). This roughly corresponds to $898183$ rows of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d047fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and filter data from the csv file\n",
    "\n",
    "# Retrieve group 1 data from the relevant CSV file\n",
    "unfiltered_goose_data = pd.read_csv('NABBP_2023_grp_01.csv')\n",
    "\n",
    "# Filter out all irrelevant species\n",
    "filtered_species = unfiltered_goose_data[(unfiltered_goose_data['SPECIES_ID'] == 1690) | (unfiltered_goose_data['SPECIES_ID'] == 1699)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7189c482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BAND             898183\n",
       "ORIGINAL_BAND    898183\n",
       "OTHER_BANDS        1551\n",
       "EVENT_DATE       898183\n",
       "EVENT_DAY        898183\n",
       "EVENT_MONTH      898183\n",
       "EVENT_YEAR       898183\n",
       "LAT_DD           897329\n",
       "LON_DD           897329\n",
       "COORD_PREC       898064\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filter unuseful columns\n",
    "\n",
    "# Keep relevant colummns\n",
    "goose_data = filtered_species[['BAND', \n",
    "                             'ORIGINAL_BAND', \n",
    "                             'OTHER_BANDS', \n",
    "                             'EVENT_DATE', \n",
    "                             'EVENT_DAY', \n",
    "                             'EVENT_MONTH', \n",
    "                             'EVENT_YEAR', \n",
    "                             'LAT_DD', \n",
    "                             'LON_DD', \n",
    "                             'COORD_PREC']]\n",
    "\n",
    "# Display number of non-null entries in each column\n",
    "display(goose_data.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999257f4",
   "metadata": {},
   "source": [
    "A large number of the date cells do not work with the `pd.to_datetime()` function. Since this is vital information for the analysis, the below cell aims specifically to clean the dates and remove any unessesary columns after. The following is the process by which dates are chosen.\n",
    "\n",
    "1. If the `'EVENT_DATE'` column already has a valid date that works with `pd.to_datetime()`, it will be the date used.\n",
    "2. Otherwise, if the `'EVENT_DAY'`, `'EVENT_MONTH'`, and `'EVENT_YEAR'` column all form a date that works with `pd.to_datetime()`, it will be the date used.\n",
    "3. If neither of the above work, `NaT` will be assigned and the row will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "023f65d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean time-related columns as described above.\n",
    "\n",
    "goose_data['EVENT_DATE'] = pd.to_datetime(goose_data['EVENT_DATE'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "# Assemble date guesses from the EVENT_MONTH, EVENT_DAY, and EVENT_YEAR columns BEFORE DROPPING THEM\n",
    "dates_from_columns = pd.to_datetime(\n",
    "    goose_data['EVENT_MONTH'].astype(str) + '/' +\n",
    "    goose_data['EVENT_DAY'].astype(str) + '/' +\n",
    "    goose_data['EVENT_YEAR'].astype(str),\n",
    "    format='%m/%d/%Y',\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "# Fill in all NaT values that can be filled with the guesses from the previous line.\n",
    "goose_data['EVENT_DATE'] = goose_data['EVENT_DATE'].fillna(dates_from_columns)\n",
    "\n",
    "# Remove all rows where EVENT_DATE is still NaT after the above operations.\n",
    "goose_data = goose_data[goose_data['EVENT_DATE'].notna()]\n",
    "\n",
    "# drop EVENT_MONTH, EVENT_DAY, and EVENT_YEAR columns\n",
    "goose_data = goose_data.drop(labels=['EVENT_MONTH', 'EVENT_DAY', 'EVENT_YEAR'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386a110c",
   "metadata": {},
   "source": [
    "Location data is also vital for analysis, so abit of cleaning will have to be done.\n",
    "\n",
    "First, rows fitting any of the following conditions will be excluded:\n",
    "\n",
    "1. Rows that do not have values for either `LAT_DD` or `LON_DD` because this issue cannot be rectified.\n",
    "2. Rows whose `COORD_PREC` values are `8`, `12`, `18`, `28`, `33`, `38`, `72` because an uncertainty given either cannot be determined or is too big to be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3435a4e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BAND</th>\n",
       "      <th>ORIGINAL_BAND</th>\n",
       "      <th>OTHER_BANDS</th>\n",
       "      <th>EVENT_DATE</th>\n",
       "      <th>LAT_DD</th>\n",
       "      <th>LON_DD</th>\n",
       "      <th>COORD_PREC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B99285787525</td>\n",
       "      <td>B99285787525</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1974-07-16</td>\n",
       "      <td>71.50000</td>\n",
       "      <td>-179.50000</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B99055198081</td>\n",
       "      <td>B99055198081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1975-07-23</td>\n",
       "      <td>71.50000</td>\n",
       "      <td>-179.50000</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B89055198948</td>\n",
       "      <td>B89055198948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1975-07-23</td>\n",
       "      <td>71.50000</td>\n",
       "      <td>-179.50000</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B59055198985</td>\n",
       "      <td>B59055198985</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1975-07-23</td>\n",
       "      <td>71.50000</td>\n",
       "      <td>-179.50000</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B59055198835</td>\n",
       "      <td>B59055198835</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1975-07-23</td>\n",
       "      <td>71.50000</td>\n",
       "      <td>-179.50000</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235635</th>\n",
       "      <td>B57965382915</td>\n",
       "      <td>B57965382915</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-11-12</td>\n",
       "      <td>43.99020</td>\n",
       "      <td>-73.33690</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235636</th>\n",
       "      <td>B57865508750</td>\n",
       "      <td>B57865508750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-11-21</td>\n",
       "      <td>44.16255</td>\n",
       "      <td>-73.31707</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235637</th>\n",
       "      <td>B47855457805</td>\n",
       "      <td>B47855457805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-11-21</td>\n",
       "      <td>44.08487</td>\n",
       "      <td>-73.33633</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235638</th>\n",
       "      <td>B58715537317</td>\n",
       "      <td>B58715537317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-09-02</td>\n",
       "      <td>44.97504</td>\n",
       "      <td>-73.31033</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235639</th>\n",
       "      <td>B77855429285</td>\n",
       "      <td>B77855429285</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-10-19</td>\n",
       "      <td>45.12932</td>\n",
       "      <td>-71.67135</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>883482 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 BAND ORIGINAL_BAND OTHER_BANDS EVENT_DATE    LAT_DD  \\\n",
       "0        B99285787525  B99285787525         NaN 1974-07-16  71.50000   \n",
       "1        B99055198081  B99055198081         NaN 1975-07-23  71.50000   \n",
       "2        B89055198948  B89055198948         NaN 1975-07-23  71.50000   \n",
       "3        B59055198985  B59055198985         NaN 1975-07-23  71.50000   \n",
       "4        B59055198835  B59055198835         NaN 1975-07-23  71.50000   \n",
       "...               ...           ...         ...        ...       ...   \n",
       "1235635  B57965382915  B57965382915         NaN 2020-11-12  43.99020   \n",
       "1235636  B57865508750  B57865508750         NaN 2020-11-21  44.16255   \n",
       "1235637  B47855457805  B47855457805         NaN 2021-11-21  44.08487   \n",
       "1235638  B58715537317  B58715537317         NaN 2022-09-02  44.97504   \n",
       "1235639  B77855429285  B77855429285         NaN 2022-10-19  45.12932   \n",
       "\n",
       "            LON_DD  COORD_PREC  \n",
       "0       -179.50000        60.0  \n",
       "1       -179.50000        60.0  \n",
       "2       -179.50000        60.0  \n",
       "3       -179.50000        60.0  \n",
       "4       -179.50000        60.0  \n",
       "...            ...         ...  \n",
       "1235635  -73.33690         0.0  \n",
       "1235636  -73.31707        11.0  \n",
       "1235637  -73.33633         0.0  \n",
       "1235638  -73.31033        11.0  \n",
       "1235639  -71.67135         0.0  \n",
       "\n",
       "[883482 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the coordinates columns as described above.\n",
    "\n",
    "# Filter out all rows where LAT_DD or LON_DD are NaN. Cannot rectify rows with this issue.\n",
    "goose_data = goose_data[goose_data['LAT_DD'].notna() & goose_data['LON_DD'].notna()]\n",
    "\n",
    "# Filter out all rows with unusable or useless coordinate precision values as outlined above.\n",
    "goose_data = goose_data[~((goose_data['COORD_PREC'] == 8)  | \\\n",
    "                     (goose_data['COORD_PREC'] == 12) | \\\n",
    "                     (goose_data['COORD_PREC'] == 18) | \\\n",
    "                     (goose_data['COORD_PREC'] == 28) | \\\n",
    "                     (goose_data['COORD_PREC'] == 33) | \\\n",
    "                     (goose_data['COORD_PREC'] == 38) | \\\n",
    "                     (goose_data['COORD_PREC'] == 72))]\n",
    "\n",
    "goose_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0b9d31",
   "metadata": {},
   "source": [
    "Additionally, a new column with lattitude and longitude uncertainties will be made whose values obey the following rules:\n",
    "\n",
    "1. If the `COORD_PREC` corresponds to an exact location (is `0`), then the uncertainty is $5 * 10^6$ to account for limits in the number of significant digits given by the data.\n",
    "2. If the `COORD_PREC` corresponds to a 1-minute block (is `1`), then the uncertainty is $\\frac{1}{120} \\approx 0.01$ degrees (rounded up) since the coordinates are in the centroid of the block.\n",
    "3. If the `COORD_PREC` corresponds to a 10-minute block (is `10`), then the uncertainty is $\\frac{1}{12} \\approx 0.1$ degrees (rounded up) since the coordinates are in the centroid of the block.\n",
    "4. If the `COORD_PREC` corresponds to a 1-degree block (is `60`), then the uncertainty is $0.5$ degrees since the coordinates are in the centroid of the block.\n",
    "5. If the `COORD_PREC` corresponds to a county (is `7`), then the uncertainty will be $0.25$ degrees by estimate (since the average county land area is 1090.69 degrees and a sqaure of that size is around $0.5$ degrees in lattitude and longitude)\n",
    "6. If the `COORD_PREC` corresponds to a town/area (is `11`), then the uncertainty will $0.25$ be degrees by estimate (since each town should be smaller than a county and thus have less uncertainty associated with it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9c69018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coord_precision(COORD_PREC):\n",
    "    if pd.isna(COORD_PREC):\n",
    "        return None  # or np.nan, or a default value like 0.5\n",
    "    if COORD_PREC == 0:\n",
    "        return 5e-6\n",
    "    elif COORD_PREC == 1:\n",
    "        return 0.01\n",
    "    elif COORD_PREC == 10:\n",
    "        return 0.1\n",
    "    elif COORD_PREC == 60:\n",
    "        return 0.5\n",
    "    elif COORD_PREC == 7 or COORD_PREC == 11:\n",
    "        return 0.25\n",
    "    else:\n",
    "        raise ValueError(f\"Unrecognized COORD_PREC value: {COORD_PREC}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1050f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the coordinate precision conversion as described above.\n",
    "\n",
    "# Compute coording uncertainties\n",
    "goose_data['COORD_UNC'] = goose_data['COORD_PREC'].apply(lambda x : get_coord_precision(x))\n",
    "\n",
    "# Drop the old column\n",
    "goose_data = goose_data.drop(labels=['COORD_PREC'], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
