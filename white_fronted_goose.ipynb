{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e39a5b2",
   "metadata": {},
   "source": [
    "# Analysis of the White Fronted Goose (Anser albifrons) and Associated Subspecies\n",
    "\n",
    "Author: Waley Wang\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "99961641",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Import nessesary libraries and do nessesary non-df related prepwork\n",
    "#\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "\n",
    "import GooseUtils\n",
    "\n",
    "\n",
    "# Supress warning related to data types (will get on first import of the csv file)\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.DtypeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bed5f07",
   "metadata": {},
   "source": [
    "Import and trim relevant data. This notebook focuses only on data related to the Anser albifrons (species id: 1710) and its subspecies Anser albifrons elgasi (species id: 1719). This roughly corresponds to $222,322$ rows of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a370be6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Retrieve the data from the csv file and filter out irrelevant species\n",
    "#\n",
    "\n",
    "# Retrieve group 1 data from the relevant CSV file\n",
    "goose_data_raw = pd.read_csv('Bird_Banding_Data/NABBP_2023_grp_01.csv')\n",
    "\n",
    "# Filter out all irrelevant species\n",
    "goose_data_raw = goose_data_raw[(goose_data_raw['SPECIES_ID'] == 1710) | (goose_data_raw['SPECIES_ID'] == 1719)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e7744b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 222322\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Get all relevant columns and display basic information about the data\n",
    "#\n",
    "\n",
    "# Retrieve all relevant columns\n",
    "goose_data = goose_data_raw[['BAND', \n",
    "                             'ORIGINAL_BAND', \n",
    "                             'OTHER_BANDS', \n",
    "                             'EVENT_DATE', \n",
    "                             'EVENT_DAY', \n",
    "                             'EVENT_MONTH', \n",
    "                             'EVENT_YEAR', \n",
    "                             'LAT_DD', \n",
    "                             'LON_DD', \n",
    "                             'COORD_PREC']]\n",
    "\n",
    "# Display number of non-null entries in each column\n",
    "print(f'Rows: {goose_data.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bba1f4c",
   "metadata": {},
   "source": [
    "## 1: Data Cleaning\n",
    "\n",
    "Here all irrelevant entries in the data are filtered out and the data is formatted for use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cc39d4",
   "metadata": {},
   "source": [
    "### 1.1: Formatting Date\n",
    "\n",
    "A large number of the date cells (~ $3,295$) do not work with the `pd.to_datetime()` function. Since this is vital information for the analysis, the below cell aims specifically to clean the dates and remove any unessesary columns after. The following is the process by which dates are chosen.\n",
    "\n",
    "1. If the `'EVENT_DATE'` column already has a valid date that works with `pd.to_datetime()`, it will be the date used.\n",
    "2. Otherwise, if the `'EVENT_DAY'`, `'EVENT_MONTH'`, and `'EVENT_YEAR'` column all form a date that works with `pd.to_datetime()`, it will be the date used.\n",
    "3. If neither of the above work, `NaT` will be assigned and the row will be dropped.\n",
    "\n",
    "\n",
    "The `'EVENT_DAY'`, `'EVENT_MONTH'`, and `'EVENT_YEAR'` columns are all updated with the relevant information (will be used for grouping later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "91df095d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 219027\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Clean time-related columns as described above.\n",
    "#\n",
    "\n",
    "# Attempt to apply pd.to_datetime() to the EVENT_DATE column.\n",
    "goose_data['EVENT_DATE'] = pd.to_datetime(goose_data['EVENT_DATE'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "# Assemble date guesses from the EVENT_MONTH, EVENT_DAY, and EVENT_YEAR columns.\n",
    "dates_from_columns = pd.to_datetime(goose_data['EVENT_MONTH'].apply(str) + '/' + goose_data['EVENT_DAY'].apply(str) + '/' + goose_data['EVENT_YEAR'].apply(str), format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "# Fill in all NaT values that can be filled with the guesses from the previous line.\n",
    "goose_data['EVENT_DATE'] = goose_data['EVENT_DATE'].fillna(dates_from_columns)\n",
    "\n",
    "# Remove all rows where EVENT_DATE is still NaT after the above operations.\n",
    "goose_data = goose_data[goose_data['EVENT_DATE'].notna()]\n",
    "\n",
    "# Ammend the EVENT_DAY, EVENT_MONTH, and EVENT_YEAR columns based on the EVENT_DATE column.\n",
    "goose_data['EVENT_DAY'] = goose_data['EVENT_DATE'].apply(lambda x: x.day)\n",
    "goose_data['EVENT_MONTH'] = goose_data['EVENT_DATE'].apply(lambda x: x.month)\n",
    "goose_data['EVENT_YEAR'] = goose_data['EVENT_DATE'].apply(lambda x: x.year)\n",
    "\n",
    "print(f'Rows: {goose_data.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6931cafd",
   "metadata": {},
   "source": [
    "### 1.2: Formatting Coordinates and Deriving a Coordinate Uncertainy\n",
    "\n",
    "Location data is also vital for analysis, so abit of cleaning will have to be done.\n",
    "\n",
    "First, rows fitting any of the following conditions will be excluded:\n",
    "1. Rows that do not have values for either `LAT_DD` or `LON_DD` because this issue cannot be rectified.\n",
    "2. Rows whose `COORD_PREC` values are `8`, `12`, `18`, `28`, `33`, `38`, `72`, or `NaN` because an uncertainty given either cannot be determined or is too big to be useful (Corresponds to $\\sim 1015$ entries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "66769a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 218012\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Clean the coordinates columns as described above.\n",
    "#\n",
    "\n",
    "# Filter out all rows where LAT_DD or LON_DD are NaN. Cannot rectify rows with this issue.\n",
    "goose_data = goose_data[goose_data['LAT_DD'].notna() & goose_data['LON_DD'].notna()]\n",
    "\n",
    "# Filter out all rows with unusable or useless coordinate precision values as outlined above.\n",
    "goose_data = goose_data[~((goose_data['COORD_PREC'] == 8)  | \\\n",
    "                     (goose_data['COORD_PREC'] == 12) | \\\n",
    "                     (goose_data['COORD_PREC'] == 18) | \\\n",
    "                     (goose_data['COORD_PREC'] == 28) | \\\n",
    "                     (goose_data['COORD_PREC'] == 33) | \\\n",
    "                     (goose_data['COORD_PREC'] == 38) | \\\n",
    "                     (goose_data['COORD_PREC'] == 72) | \\\n",
    "                     (goose_data['COORD_PREC'].isna()))]\n",
    "\n",
    "print(f'Rows: {goose_data.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68c7b3d",
   "metadata": {},
   "source": [
    "Additionally, a new column with lattitude and longitude uncertainties will be made whose values obey the following rules:\n",
    "1. If the `COORD_PREC` corresponds to an exact location (is `0`), then the uncertainty is $5*10^{6}$ to account for limits in the number of significant digits given by the data.\n",
    "2. If the `COORD_PREC` corresponds to a 1-minute block (is `1`), then the uncertainty is $\\frac{1}{120} \\approx 0.01$ degrees (rounded up) since the coordinates are in the centroid of the block.\n",
    "3. If the `COORD_PREC` corresponds to a 10-minute block (is `10`), then the uncertainty is $\\frac{1}{12} \\approx 0.1$ degrees (rounded up) since the coordinates are in the centroid of the block.\n",
    "4. If the `COORD_PREC` corresponds to a 1-degree block (is `60`), then the uncertainty is $0.5$ degrees since the coordinates are in the centroid of the block.\n",
    "5. If the `COORD_PREC` corresponds to a county (is `7`), then the uncertainty will be $0.25$ degrees by estimate (since the average county land area is 1090.69 degrees and a sqaure of that size is around $0.5$ degrees in lattitude and longitude)\n",
    "6. If the `COORD_PREC` corresponds to a town/area (is `11`), then the uncertainty will be $0.25$ degrees by estimate (since each town should be smaller than a county and thus have less uncertainty associated with it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f1ea95e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Perform the coordinate precision conversion as described above.\n",
    "#\n",
    "\n",
    "# Compute coording uncertainties\n",
    "goose_data['COORD_UNC'] = goose_data['COORD_PREC'].apply(lambda x : GooseUtils.get_coord_unc(x))\n",
    "\n",
    "# Drop the old column\n",
    "goose_data = goose_data.drop(labels=['COORD_PREC'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f785439",
   "metadata": {},
   "source": [
    "## 2: Perliminary Analysis\n",
    "\n",
    "### 2.1: Question 1: Does the White Fronted Goose Actually Migrate?\n",
    "\n",
    "For this, we will compare the average location of the bird over all datapoints taken within each month of the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5c643ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month: 1 - Rows: 6933\n",
      "Month: 2 - Rows: 1720\n",
      "Month: 3 - Rows: 2983\n",
      "Month: 4 - Rows: 1082\n",
      "Month: 5 - Rows: 362\n",
      "Month: 6 - Rows: 4749\n",
      "Month: 7 - Rows: 148863\n",
      "Month: 8 - Rows: 7582\n",
      "Month: 9 - Rows: 14402\n",
      "Month: 10 - Rows: 15366\n",
      "Month: 11 - Rows: 7557\n",
      "Month: 12 - Rows: 6413\n"
     ]
    }
   ],
   "source": [
    "months_dict = goose_data.groupby('EVENT_MONTH')\n",
    "\n",
    "for month, group in months_dict:\n",
    "    print(f'Month: {month} - Rows: {group.shape[0]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
