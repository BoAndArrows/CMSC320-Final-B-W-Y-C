{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b627482",
   "metadata": {},
   "source": [
    "## 0: Loading Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9566c6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Import the necessary modules\n",
    "#\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "import scipy.stats as stats\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime\n",
    "\n",
    "import calendar\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "import GooseUtils\n",
    "\n",
    "# Supress warning related to data types (will get on first import of the csv file)\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.DtypeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3decb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Retrieve the data from the csv file and filter out irrelevant species\n",
    "#\n",
    "\n",
    "# Retrieve group 1 data from the relevant CSV file\n",
    "grp1_goose_data_raw = pd.read_csv('Bird_Banding_Data/NABBP_2023_grp_01.csv')\n",
    "grp2_goose_data_raw = pd.read_csv('Bird_Banding_Data/NABBP_2023_grp_02.csv', on_bad_lines='skip')\n",
    "grp3_goose_data_raw = pd.read_csv('Bird_Banding_Data/NABBP_2023_grp_03.csv')\n",
    "\n",
    "\n",
    "# Filter out irrelevant columns from the dataframes\n",
    "relevant_cols = ['BAND', \n",
    "                 'ORIGINAL_BAND', \n",
    "                 'OTHER_BANDS', \n",
    "                 'EVENT_DATE', \n",
    "                 'EVENT_DAY', \n",
    "                 'EVENT_MONTH', \n",
    "                 'EVENT_YEAR', \n",
    "                 'LAT_DD', \n",
    "                 'LON_DD', \n",
    "                 'COORD_PREC',\n",
    "                 'SPECIES_ID',]\n",
    "\n",
    "grp1_goose_data_raw = grp1_goose_data_raw[relevant_cols]\n",
    "grp2_goose_data_raw = grp2_goose_data_raw[relevant_cols]\n",
    "grp3_goose_data_raw = grp3_goose_data_raw[relevant_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d05e1bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve dataframes for each species\n",
    "white_fronted_goose_data_raw = (grp1_goose_data_raw[(grp1_goose_data_raw['SPECIES_ID'] == 1710) | \\\n",
    "                                                   (grp1_goose_data_raw['SPECIES_ID'] == 1719)]).drop(labels='SPECIES_ID', axis=1)\n",
    "snow_goose_data_raw = (grp1_goose_data_raw[(grp1_goose_data_raw['SPECIES_ID'] == 1690) | \\\n",
    "                                          (grp1_goose_data_raw['SPECIES_ID'] == 1699) | \\\n",
    "                                          (grp1_goose_data_raw['SPECIES_ID'] == 1691) | \\\n",
    "                                          (grp1_goose_data_raw['SPECIES_ID'] == 1698)]).drop(labels='SPECIES_ID', axis=1)\n",
    "cackling_goose_data_raw = (grp3_goose_data_raw[(grp3_goose_data_raw['SPECIES_ID'] == 1721) | \\\n",
    "                                             (grp3_goose_data_raw['SPECIES_ID'] == 1722)]).drop(labels='SPECIES_ID', axis=1)\n",
    "\n",
    "cg_grp3_data = grp3_goose_data_raw[(grp3_goose_data_raw['SPECIES_ID'] == 1729) | \\\n",
    "                                   (grp3_goose_data_raw['SPECIES_ID'] == 1723)]\n",
    "canada_goose_data_raw = pd.concat([grp2_goose_data_raw, cg_grp3_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d9295d",
   "metadata": {},
   "source": [
    "## 1: Data Cleaning\n",
    "\n",
    "Here all irrelevant entries in the data are filtered out and the data is formatted for use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1df96a",
   "metadata": {},
   "source": [
    "### 1.1: Formatting Date\n",
    "\n",
    "A large number of the date cells (~ $3,295$) do not work with the `pd.to_datetime()` function. Since this is vital information for the analysis, the below cell aims specifically to clean the dates and remove any unessesary columns after. The following is the process by which dates are chosen.\n",
    "\n",
    "1. If the `'EVENT_DATE'` column already has a valid date that works with `pd.to_datetime()`, it will be the date used.\n",
    "2. Otherwise, if the `'EVENT_DAY'`, `'EVENT_MONTH'`, and `'EVENT_YEAR'` column all form a date that works with `pd.to_datetime()`, it will be the date used.\n",
    "3. If neither of the above work, `NaT` will be assigned and the row will be dropped.\n",
    "\n",
    "\n",
    "The `'EVENT_DAY'`, `'EVENT_MONTH'`, and `'EVENT_YEAR'` columns are all updated with the relevant information (will be used for grouping later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a371f184",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Clean the datetime columns\n",
    "#\n",
    "\n",
    "# Perfomes datetime cleaning\n",
    "def clean_datetime(goose_data):\n",
    "    goose_data['EVENT_DATE'] = pd.to_datetime(goose_data['EVENT_DATE'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "    # Assemble date guesses from the EVENT_MONTH, EVENT_DAY, and EVENT_YEAR columns BEFORE DROPPING THEM\n",
    "    dates_from_columns = pd.to_datetime(\n",
    "        goose_data['EVENT_MONTH'].astype(str) + '/' +\n",
    "        goose_data['EVENT_DAY'].astype(str) + '/' +\n",
    "        goose_data['EVENT_YEAR'].astype(str),\n",
    "        format='%m/%d/%Y',\n",
    "        errors='coerce'\n",
    "    )\n",
    "\n",
    "    # Fill in all NaT values that can be filled with the guesses from the previous line.\n",
    "    goose_data['EVENT_DATE'] = goose_data['EVENT_DATE'].fillna(dates_from_columns)\n",
    "\n",
    "    # Remove all rows where EVENT_DATE is still NaT after the above operations.\n",
    "    goose_data = goose_data[goose_data['EVENT_DATE'].notna()]\n",
    "\n",
    "    # drop EVENT_MONTH, EVENT_DAY, and EVENT_YEAR columns\n",
    "    goose_data = goose_data.drop(labels=['EVENT_MONTH', 'EVENT_DAY', 'EVENT_YEAR'], axis=1)\n",
    "\n",
    "    return goose_data\n",
    "\n",
    "white_fronted_goose_data_raw = clean_datetime(white_fronted_goose_data_raw)\n",
    "snow_goose_data_raw = clean_datetime(snow_goose_data_raw)\n",
    "cackling_goose_data_raw = clean_datetime(cackling_goose_data_raw)\n",
    "canada_goose_data_raw = clean_datetime(canada_goose_data_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f7c462",
   "metadata": {},
   "source": [
    "### 1.2: Formatting Coordinates and Deriving a Coordinate Uncertainy\n",
    "\n",
    "Location data is also vital for analysis, so abit of cleaning will have to be done.\n",
    "\n",
    "First, rows fitting any of the following conditions will be excluded:\n",
    "1. Rows that do not have values for either `LAT_DD` or `LON_DD` because this issue cannot be rectified.\n",
    "2. Rows whose `COORD_PREC` values are `8`, `12`, `18`, `28`, `33`, `38`, `72`, or `NaN` because an uncertainty given either cannot be determined or is too big to be useful (Corresponds to $\\sim 1015$ entries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f44c1c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Clean the coordinates columns as described above.\n",
    "#\n",
    "\n",
    "# Perform location cleaning\n",
    "def clean_location(goose_data):\n",
    "    # Filter out all rows where LAT_DD or LON_DD are NaN. Cannot rectify rows with this issue.\n",
    "    goose_data = goose_data[goose_data['LAT_DD'].notna() & goose_data['LON_DD'].notna()]\n",
    "\n",
    "    # Filter out all rows with unusable or useless coordinate precision values as outlined above.\n",
    "    goose_data = goose_data[~((goose_data['COORD_PREC'] == 8)  | \\\n",
    "                              (goose_data['COORD_PREC'] == 12) | \\\n",
    "                              (goose_data['COORD_PREC'] == 18) | \\\n",
    "                              (goose_data['COORD_PREC'] == 28) | \\\n",
    "                              (goose_data['COORD_PREC'] == 33) | \\\n",
    "                              (goose_data['COORD_PREC'] == 38) | \\\n",
    "                              (goose_data['COORD_PREC'] == 72) | \\\n",
    "                              (goose_data['COORD_PREC'].isna()))]\n",
    "\n",
    "    goose_data = goose_data[(goose_data['LAT_DD'] != 0.0) | (goose_data['LON_DD'] != 0.0)]\n",
    "\n",
    "    return goose_data\n",
    "\n",
    "white_fronted_goose_data_raw = clean_location(white_fronted_goose_data_raw)\n",
    "snow_goose_data_raw = clean_location(snow_goose_data_raw)\n",
    "cackling_goose_data_raw = clean_location(cackling_goose_data_raw)\n",
    "canada_goose_data_raw = clean_location(canada_goose_data_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f878a3b7",
   "metadata": {},
   "source": [
    "Additionally, a new column with lattitude and longitude uncertainties will be made whose values obey the following rules:\n",
    "1. If the `COORD_PREC` corresponds to an exact location (is `0`), then the uncertainty is $5*10^{6}$ to account for limits in the number of significant digits given by the data.\n",
    "2. If the `COORD_PREC` corresponds to a 1-minute block (is `1`), then the uncertainty is $\\frac{1}{120} \\approx 0.01$ degrees (rounded up) since the coordinates are in the centroid of the block.\n",
    "3. If the `COORD_PREC` corresponds to a 10-minute block (is `10`), then the uncertainty is $\\frac{1}{12} \\approx 0.1$ degrees (rounded up) since the coordinates are in the centroid of the block.\n",
    "4. If the `COORD_PREC` corresponds to a 1-degree block (is `60`), then the uncertainty is $0.5$ degrees since the coordinates are in the centroid of the block.\n",
    "5. If the `COORD_PREC` corresponds to a county (is `7`), then the uncertainty will be $0.25$ degrees by estimate (since the average county land area is 1090.69 degrees and a sqaure of that size is around $0.5$ degrees in lattitude and longitude)\n",
    "6. If the `COORD_PREC` corresponds to a town/area (is `11`), then the uncertainty will be $0.25$ degrees by estimate (since each town should be smaller than a county and thus have less uncertainty associated with it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f24fdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Perform the coordinate precision conversion as described above.\n",
    "#\n",
    "\n",
    "def convert_coord_precision(goose_data):\n",
    "    # Compute coording uncertainties\n",
    "    goose_data['COORD_UNC'] = goose_data['COORD_PREC'].apply(lambda x : GooseUtils.get_coord_unc(x))\n",
    "\n",
    "    # Drop the old column\n",
    "    goose_data = goose_data.drop(labels=['COORD_PREC'], axis=1)\n",
    "\n",
    "    return goose_data\n",
    "\n",
    "white_fronted_goose_data_raw = convert_coord_precision(white_fronted_goose_data_raw)\n",
    "snow_goose_data_raw = convert_coord_precision(snow_goose_data_raw) \n",
    "cackling_goose_data_raw = convert_coord_precision(cackling_goose_data_raw)\n",
    "canada_goose_data_raw = convert_coord_precision(canada_goose_data_raw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
